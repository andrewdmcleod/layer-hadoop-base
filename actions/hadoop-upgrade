#!/bin/bash
action-set charmdir.before=${CHARM_DIR}
export SAVEPATH=$PATH
. /etc/environment
export PATH=$PATH:$SAVEPATH
export JAVA_HOME

current_hadoop_ver=`/usr/lib/hadoop/bin/hadoop version|head -n1|awk '{print $2}'`
config_hadoop_ver=`config-get hadoop_version`
new_hadoop_ver=`action-get version`
cpu_arch=`lscpu|grep -i arch|awk '{print $2}'`
rollback=`action-get rollback`

function init_procs () { 
        # stop or start hadoop procs (jps procs)
        if [ $1 == "stop" ] ; then
                i=0
                unset hadoop_procs
                while read -r line ; do
                        hadoop_procs[i]=$(echo $line|awk '{print $2}') ; ((i++)) 
                done < <(sudo jps|grep -vi jps)
        fi
        for proc in ${hadoop_procs[@]} ; do 
                if [ $proc == "NameNode" ] && [ $1 == "start" ] ; then
                        su hdfs -c "hdfs namenode -rollingUpgrade started &" 
                else
                        su hdfs -c "hadoop-daemon.sh $1 $proc"
                fi
        done
        sleep 2
}

function check_procs () {
        if pgrep -f Dproc_ ; then
                action-set result="hadoop process detected, upgrade aborted"
                status-set active "hadoop process detected, upgrade aborted"
                exit 1
        fi
}

if ! [ "$new_hadoop_ver" == "$config_hadoop_ver" ] ; then
        action-set result="Version specified does not math configured version, aborting"
        action-fail "Version specified does not math configured version"
        exit 1
fi

if [ "$new_hadoop_ver" == "$current_hadoop_ver" ] ; then
        action-set result="Same version already installed, aborting"
        action-fail "Same version already installed"
        exit 1
fi

init_procs stop
if [ "${rollback}" == "True" ] ; then
        if [ -d /usr/lib/hadoop-${new_hadoop_ver} ] ; then
                rm /usr/lib/hadoop
                ln -s /usr/lib/hadoop-${new_hadoop_ver} /usr/lib/hadoop
                if [ -d /usr/lib/hadoop-${current_hadoop_ver}/logs ] ; then
                        mv /usr/lib/hadoop-${current_hadoop_ver}/logs /usr/lib/hadoop/
                fi
                action-set newhadoop.rollback="successfully rolled back"
                status-set active "Ready - rollback to ${new_hadoop_ver} complete - ready for hadoop-post-upgrade"
                init_procs start
                exit 0
        else
                action-set newhadoop.rollback="previous version not found, unpacking..."
                status-set active "previous version not found, unpacking..."
        fi
fi

status-set maintenance "Fetching hadoop-${new_hadoop_ver}-${cpu_arch}"
juju-resources fetch hadoop-${new_hadoop_ver}-${cpu_arch}
if [ ! $? -eq 0 ] ; then
        action-set newhadoop.fetch="fail"
        init_procs start
        exit 1
fi
action-set newhadoop.fetch="success"

status-set maintenance "Verifying hadoop-${new_hadoop_ver}-${cpu_arch}"
juju-resources verify hadoop-${new_hadoop_ver}-${cpu_arch}
if [ ! $? -eq 0 ] ; then
        action-set newhadoop.verify="fail"
        init_procs start
        exit 1
fi
action-set newhadoop.verify="success"

new_hadoop_path=`juju-resources resource_path hadoop-${new_hadoop_ver}-${cpu_arch}`
if [ -h /usr/lib/hadoop ] ; then
       rm /usr/lib/hadoop
fi

mv /usr/lib/hadoop/ /usr/lib/hadoop-${current_hadoop_ver}
ln -s /usr/lib/hadoop-${current_hadoop_ver}/ /usr/lib/hadoop
current_hadoop_path=hadoop-${current_hadoop_ver}

status-set maintenance "Extracting hadoop-${new_hadoop_ver}-${cpu_arch}"
tar -zxvf ${new_hadoop_path} -C /usr/lib/
if [ $? -eq 0 ] ; then
        if [ -h /usr/lib/hadoop ] ; then
                rm /usr/lib/hadoop
        fi
        ln -s /usr/lib/hadoop-${new_hadoop_ver} /usr/lib/hadoop
fi
if [ -d ${current_hadoop_path}/logs ] ; then
        mv ${current_hadoop_path}/logs ${new_hadoop_path}/
fi
action-set charmdir.after=${CHARM_DIR}
# set hadoop.version in unitdata
chlp unitdata set hadoop.version ${new_hadoop_ver}

hooks/refresh-spec
action-set result="complete"
status-set maintenance "hadoop version ${new_hadoop_ver} installed - ready for hadoop-post-upgrade"
init_procs start
